# coding=utf-8
"""
AI åˆ†æå™¨æ¨¡å—

è°ƒç”¨ AI å¤§æ¨¡å‹å¯¹çƒ­ç‚¹æ–°é—»è¿›è¡Œæ·±åº¦åˆ†æ
æ”¯æŒ OpenAIã€Google Geminiã€Azure OpenAI ç­‰å…¼å®¹æ¥å£
"""

import json
import os
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Callable, Dict, List, Optional

from trendradar.researcher import Researcher

@dataclass
class AIAnalysisResult:
    """AI åˆ†æç»“æœ"""
    summary: str = ""                    # çƒ­ç‚¹è¶‹åŠ¿æ¦‚è¿°
    keyword_analysis: str = ""           # å…³é”®è¯çƒ­åº¦åˆ†æ
    sentiment: str = ""                  # æƒ…æ„Ÿå€¾å‘åˆ†æ
    cross_platform: str = ""             # è·¨å¹³å°å…³è”
    impact: str = ""                     # æ½œåœ¨å½±å“è¯„ä¼°
    signals: str = ""                    # å€¼å¾—å…³æ³¨çš„ä¿¡å·
    conclusion: str = ""                 # æ€»ç»“ä¸å»ºè®®
    raw_response: str = ""               # åŸå§‹å“åº”
    success: bool = False                # æ˜¯å¦æˆåŠŸ
    error: str = ""                      # é”™è¯¯ä¿¡æ¯
    # æ–°é—»æ•°é‡ç»Ÿè®¡
    total_news: int = 0                  # æ€»æ–°é—»æ•°ï¼ˆçƒ­æ¦œ+RSSï¼‰
    analyzed_news: int = 0               # å®é™…åˆ†æçš„æ–°é—»æ•°
    max_news_limit: int = 0              # åˆ†æä¸Šé™é…ç½®å€¼
    hotlist_count: int = 0               # çƒ­æ¦œæ–°é—»æ•°
    rss_count: int = 0                   # RSS æ–°é—»æ•°


class AIAnalyzer:
    """AI åˆ†æå™¨"""

    def __init__(self, config: Dict[str, Any], get_time_func: Callable):
        """
        åˆå§‹åŒ– AI åˆ†æå™¨
        """
        self.config = config
        self.get_time_func = get_time_func

        # ä»é…ç½®æˆ–ç¯å¢ƒå˜é‡è·å– API Key
        self.api_key = config.get("API_KEY") or os.environ.get("AI_API_KEY", "")
        self.provider = config.get("PROVIDER", "openai")
        self.model = config.get("MODEL", "gpt-4o-mini")
        self.base_url = config.get("BASE_URL", "")
        self.timeout = config.get("TIMEOUT", 90)
        self.max_news = config.get("MAX_NEWS_FOR_ANALYSIS", 50)
        self.include_rss = config.get("INCLUDE_RSS", True)
        self.push_mode = config.get("PUSH_MODE", "both")

        # åˆå§‹åŒ–æ·±åº¦ç ”ç©¶æ¨¡å—
        self.researcher = Researcher(config.get("DEEP_RESEARCH", {}))

        # åŠ è½½æç¤ºè¯æ¨¡æ¿
        self.system_prompt, self.user_prompt_template = self._load_prompt_template(
            config.get("PROMPT_FILE", "ai_analysis_prompt.txt")
        )

    def _load_prompt_template(self, prompt_file: str) -> tuple:
        """åŠ è½½æç¤ºè¯æ¨¡æ¿"""
        config_dir = Path(__file__).parent.parent.parent / "config"
        prompt_path = config_dir / prompt_file

        if not prompt_path.exists():
            print(f"[AI] æç¤ºè¯æ–‡ä»¶ä¸å­˜åœ¨: {prompt_path}")
            return "", ""

        content = prompt_path.read_text(encoding="utf-8")

        # è§£æ [system] å’Œ [user] éƒ¨åˆ†
        system_prompt = ""
        user_prompt = ""

        if "[system]" in content and "[user]" in content:
            parts = content.split("[user]")
            system_part = parts[0]
            user_part = parts[1] if len(parts) > 1 else ""

            # æå– system å†…å®¹
            if "[system]" in system_part:
                system_prompt = system_part.split("[system]")[1].strip()

            user_prompt = user_part.strip()
        else:
            user_prompt = content

        return system_prompt, user_prompt

    def analyze(
        self,
        stats: List[Dict],
        rss_stats: Optional[List[Dict]] = None,
        report_mode: str = "daily",
        report_type: str = "å½“æ—¥æ±‡æ€»",
        platforms: Optional[List[str]] = None,
        keywords: Optional[List[str]] = None,
    ) -> AIAnalysisResult:
        """æ‰§è¡Œ AI åˆ†æ"""
        if not self.api_key:
            return AIAnalysisResult(
                success=False,
                error="æœªé…ç½® AI API Keyï¼Œè¯·åœ¨ config.yaml æˆ–ç¯å¢ƒå˜é‡ AI_API_KEY ä¸­è®¾ç½®"
            )

        # å‡†å¤‡æ–°é—»å†…å®¹å¹¶è·å–ç»Ÿè®¡æ•°æ®
        news_content, hotlist_total, rss_total, analyzed_count = self._prepare_news_content(stats, rss_stats)
        total_news = hotlist_total + rss_total

        if not news_content:
            return AIAnalysisResult(
                success=False,
                error="æ²¡æœ‰å¯åˆ†æçš„æ–°é—»å†…å®¹",
                total_news=total_news,
                hotlist_count=hotlist_total,
                rss_count=rss_total,
                analyzed_news=0,
                max_news_limit=self.max_news
            )

        # æ„å»ºæç¤ºè¯
        current_time = self.get_time_func().strftime("%Y-%m-%d %H:%M:%S")

        if not keywords:
            keywords = [s.get("word", "") for s in stats if s.get("word")] if stats else []

        user_prompt = self.user_prompt_template
        user_prompt = user_prompt.replace("{report_mode}", report_mode)
        user_prompt = user_prompt.replace("{report_type}", report_type)
        user_prompt = user_prompt.replace("{current_time}", current_time)
        user_prompt = user_prompt.replace("{news_count}", str(hotlist_total))
        user_prompt = user_prompt.replace("{rss_count}", str(rss_total))
        user_prompt = user_prompt.replace("{platforms}", ", ".join(platforms) if platforms else "å¤šå¹³å°")
        user_prompt = user_prompt.replace("{keywords}", ", ".join(keywords[:20]) if keywords else "æ— ")
        user_prompt = user_prompt.replace("{news_content}", news_content)

        try:
            response = self._call_ai_api(user_prompt)
            result = self._parse_response(response)
            result.total_news = total_news
            result.hotlist_count = hotlist_total
            result.rss_count = rss_total
            result.analyzed_news = analyzed_count
            result.max_news_limit = self.max_news
            return result
        except Exception as e:
            import requests
            error_type = type(e).__name__
            error_msg = str(e)
            if isinstance(e, requests.exceptions.Timeout):
                friendly_msg = f"AI API è¯·æ±‚è¶…æ—¶ï¼ˆ{self.timeout}ç§’ï¼‰"
            elif isinstance(e, requests.exceptions.ConnectionError):
                friendly_msg = "æ— æ³•è¿æ¥åˆ° AI API"
            else:
                friendly_msg = f"AI åˆ†æå¤±è´¥ ({error_type}): {error_msg[:150]}"
            return AIAnalysisResult(success=False, error=friendly_msg)

    def _prepare_news_content(
        self,
        stats: List[Dict],
        rss_stats: Optional[List[Dict]] = None,
    ) -> tuple:
        """å‡†å¤‡æ–°é—»å†…å®¹æ–‡æœ¬ï¼ˆTavily å¢å¼ºç‰ˆï¼‰"""
        lines = []
        count = 0
        
        # ç»Ÿè®¡æ€»æ•°ï¼ˆç”¨äºè¿”å›ï¼‰
        hotlist_total = sum(len(s.get("titles", [])) for s in stats) if stats else 0
        rss_total = sum(len(s.get("titles", [])) for s in rss_stats) if rss_stats else 0

        # --- ç¬¬ä¸€éƒ¨åˆ†ï¼šå¤„ç† RSS è®¢é˜…ï¼ˆé€šå¸¸ä»·å€¼æ›´é«˜ï¼Œä¼˜å…ˆå¤„ç†æˆ–ç¡®ä¿å¤„ç†ï¼‰ ---
        if self.include_rss and rss_stats:
            lines.append("\n### RSS é‡ç‚¹è¿½è¸ª (æ·±åº¦å¢å¼º)")
            for stat in rss_stats:
                titles = stat.get("titles", [])
                for t in titles:
                    title = t.get("title", "")
                    if not title: continue
                    
                    # åªè¦æ˜¯ RSSï¼Œå°±å°è¯•æœç´¢ï¼ˆæˆ–è€…åœ¨è¿™é‡ŒåŠ å…¥ä½ çš„ä¿é™©å…³é”®è¯åˆ¤æ–­ï¼‰
                    extra_info = ""
                    if self.researcher.enabled:
                        # è¿™é‡Œä¼šè°ƒç”¨ä½ é…ç½®çš„ Tavily
                        extra_info = self.researcher.search_and_research(title) 

                    source = t.get("source_name", "RSSæº")
                    line = f"- [{source}] {title}"
                    if extra_info:
                        # å°† Tavily æœåˆ°çš„æ­£æ–‡æ‘˜è¦ç›´æ¥æŒ‚è½½
                        line += f"\n  â””â”€ ğŸ” [æ·±åº¦èƒŒæ™¯]: {extra_info}"
                    
                    lines.append(line)
                    count += 1
                    if count >= self.max_news: break
                if count >= self.max_news: break

        # --- ç¬¬äºŒéƒ¨åˆ†ï¼šå¤„ç†çƒ­æ¦œå†…å®¹ ---
        if stats and count < self.max_news:
            lines.append("\n### ç¤¾äº¤çƒ­æ¦œè¶‹åŠ¿")
            for stat in stats:
                word = stat.get("word", "")
                titles = stat.get("titles", [])
                if word and titles:
                    for t in titles:
                        title = t.get("title", "")
                        if not title: continue
                        
                        # çƒ­æ¦œæ¯”è¾ƒæ‚ï¼Œå»ºè®®åªå¯¹åŒ¹é…å…³é”®è¯çš„è¿›è¡Œæœç´¢
                        extra_info = ""
                        # æ£€æŸ¥æ ‡é¢˜é‡Œæ˜¯å¦æœ‰ä½ å…³å¿ƒçš„è¯ï¼Œæ¯”å¦‚ 'ä¿é™©', 'AI', 'å®‰å…¨'
                        if any(k.lower() in title.lower() for k in ["ä¿é™©", "AI", "å®‰å…¨", "é™©"]):
                            extra_info = self.researcher.search_and_research(title)

                        source = t.get("source_name", "çƒ­æ¦œ")
                        line = f"- [{source}] {title}"
                        if extra_info:
                            line += f"\n  â””â”€ ğŸ” [æ·±åº¦èƒŒæ™¯]: {extra_info}"
                        
                        lines.append(line)
                        count += 1
                        if count >= self.max_news: break
                if count >= self.max_news: break

        return "\n".join(lines), hotlist_total, rss_total, count

    def _format_time_range(self, first_time: str, last_time: str) -> str:
        """æ ¼å¼åŒ–æ—¶é—´èŒƒå›´"""
        def extract_time(time_str: str) -> str:
            if not time_str: return "-"
            if " " in time_str:
                parts = time_str.split(" ")
                if len(parts) >= 2:
                    time_part = parts[1]
                    if ":" in time_part: return time_part[:5]
            elif ":" in time_str:
                return time_str[:5]
            return time_str[:5] if len(time_str) >= 5 else time_str

        first = extract_time(first_time)
        last = extract_time(last_time)
        if first == last or last == "-": return first
        return f"{first}~{last}"

    def _call_ai_api(self, user_prompt: str) -> str:
        """è°ƒç”¨ AI API"""
        if self.provider == "gemini":
            return self._call_gemini(user_prompt)
        return self._call_openai_compatible(user_prompt)

    def _get_api_url(self) -> str:
        """è·å–å®Œæ•´ API URL"""
        if self.base_url: return self.base_url
        urls = {
            "deepseek": "https://api.deepseek.com/v1/chat/completions",
            "openai": "https://api.openai.com/v1/chat/completions",
        }
        url = urls.get(self.provider)
        if not url:
            raise ValueError(f"{self.provider} éœ€è¦é…ç½® base_url")
        return url

    def _call_openai_compatible(self, user_prompt: str) -> str:
        """è°ƒç”¨ OpenAI å…¼å®¹æ¥å£"""
        import requests
        url = self._get_api_url()
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json",
        }
        messages = []
        if self.system_prompt:
            messages.append({"role": "system", "content": self.system_prompt})
        messages.append({"role": "user", "content": user_prompt})

        payload = {
            "model": self.model,
            "messages": messages,
            "temperature": 0.7,
            "max_tokens": 2000,
        }
        response = requests.post(url, headers=headers, json=payload, timeout=self.timeout)
        response.raise_for_status()
        return response.json()["choices"][0]["message"]["content"]

    def _call_gemini(self, user_prompt: str) -> str:
        """è°ƒç”¨ Google Gemini API"""
        import requests
        model = self.model or "gemini-1.5-flash"
        url = f"https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent?key={self.api_key}"
        headers = {"Content-Type": "application/json"}
        contents = []
        if self.system_prompt:
            contents.append({"role": "user", "parts": [{"text": f"System instruction: {self.system_prompt}"}]})
            contents.append({"role": "model", "parts": [{"text": "Understood."}]})
        contents.append({"role": "user", "parts": [{"text": user_prompt}]})
        payload = {"contents": contents, "generationConfig": {"temperature": 0.7, "maxOutputTokens": 2000}}
        response = requests.post(url, headers=headers, json=payload, timeout=self.timeout)
        response.raise_for_status()
        return response.json()["candidates"][0]["content"]["parts"][0]["text"]

    def _parse_response(self, response: str) -> AIAnalysisResult:
        """è§£æ AI å“åº”"""
        result = AIAnalysisResult(raw_response=response)
        if not response or not response.strip():
            result.error = "AI è¿”å›ç©ºå“åº”"
            return result

        try:
            json_str = response
            if "```json" in response:
                json_str = response.split("```json", 1)[1].split("```", 1)[0]
            elif "```" in response:
                json_str = response.split("```", 2)[1]

            data = json.loads(json_str.strip())
            result.summary = data.get("summary", "")
            result.keyword_analysis = data.get("keyword_analysis", "")
            result.sentiment = data.get("sentiment", "")
            result.cross_platform = data.get("cross_platform", "")
            result.impact = data.get("impact", "")
            result.signals = data.get("signals", "")
            result.conclusion = data.get("conclusion", "")
            result.success = True
        except Exception as e:
            result.error = f"è§£æé”™è¯¯: {str(e)}"
            result.summary = response[:1000]
            result.success = True
        return result
